{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports-and-data-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr, chi2_contingency\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import shap\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "data-preparation",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'significant_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 96\u001b[39m\n\u001b[32m     93\u001b[39m     df[col] = df[col].replace({\u001b[33m'\u001b[39m\u001b[33mFriendly\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mGood\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mVery good\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mGood\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPoor\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mBad\u001b[39m\u001b[33m'\u001b[39m})\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# Use significant features for preprocessing, fallback to all if none are significant\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m selected_features = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(significant_features)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msignificant_features\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m numerical_cols + binary_cols + ordinal_cols + categorical_cols\n\u001b[32m     97\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSelected features for preprocessing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Update column lists to include only significant features\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'significant_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Data for Postpartum Depression Prediction in Bangladesh/PPD_dataset.csv')\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.replace(\"’\", \"'\").str.replace(\"‘\", \"'\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(['sr', 'PHQ9 Score', 'EPDS Score'], axis=1)\n",
    "\n",
    "# Fix: Standardize category text to match exactly in ordinal_categories\n",
    "df['Total children'] = df['Total children'].str.lower().str.strip()\n",
    "df['Total children'] = df['Total children'].replace({\n",
    "    'more than two': 'More than two',  # Capitalize M to match ordinal_categories\n",
    "    'more than Two': 'More than two'   # just in case\n",
    "})\n",
    "\n",
    "# Check for 'Received Support' vs 'Recieved Support'\n",
    "if 'Received Support' in df.columns and 'Recieved Support' not in df.columns:\n",
    "    df = df.rename(columns={'Received Support': 'Recieved Support'})\n",
    "\n",
    "# Define columns\n",
    "numerical_cols = ['Age', 'Number of the latest pregnancy']\n",
    "binary_cols = [\n",
    "    'Residence', 'Marital status', 'Family type', 'Pregnancy plan', 'Regular checkups',\n",
    "    'Fear of pregnancy', 'Mode of delivery', 'Gender of newborn', 'Birth compliancy',\n",
    "    'Breastfeed', 'Newborn illness', 'Worry about newborn', 'Relax/sleep when newborn is tended',\n",
    "    'Relax/sleep when the newborn is asleep', 'Angry after latest child birth',\n",
    "    'Depression before pregnancy', 'Depression during pregnancy', 'Major changes or losses during pregnancy',\n",
    "    'Abuse', 'Trust and share feelings'\n",
    "]\n",
    "ordinal_cols = [\n",
    "    'Monthly income before latest pregnancy', 'Current monthly income', \"Husband's monthly income\",\n",
    "    'Total children', 'Number of household members', 'Pregnancy length', 'Age of newborn',\n",
    "    'Age of immediate older children', 'Recieved Support', 'Need for Support',\n",
    "    'Relationship with the in-laws', 'Relationship with husband', 'Relationship with the newborn',\n",
    "    'Relationship between father and newborn', 'Feeling about motherhood'\n",
    "]\n",
    "categorical_cols = [\n",
    "    'Education Level', 'Occupation before latest pregnancy', 'Occupation After Your Latest Childbirth',\n",
    "    \"Husband's education level\", 'Addiction', 'Disease before pregnancy', 'History of pregnancy loss',\n",
    "    'Diseases during pregnancy', 'Feeling for regular activities'\n",
    "]\n",
    "\n",
    "# Binary mappings\n",
    "binary_mappings = {\n",
    "    'Residence': {'City': 0, 'Village': 1},\n",
    "    'Marital status': {'Married': 0, 'Divorced': 1},\n",
    "    'Family type': {'Nuclear': 0, 'Joint': 1},\n",
    "    'Pregnancy plan': {'No': 0, 'Yes': 1},\n",
    "    'Regular checkups': {'No': 0, 'Yes': 1},\n",
    "    'Fear of pregnancy': {'No': 0, 'Yes': 1},\n",
    "    'Mode of delivery': {'Normal Delivery': 0, 'Caesarean Section': 1},\n",
    "    'Gender of newborn': {'Boy': 0, 'Girl': 1},\n",
    "    'Birth compliancy': {'No': 0, 'Yes': 1},\n",
    "    'Breastfeed': {'No': 0, 'Yes': 1},\n",
    "    'Newborn illness': {'No': 0, 'Yes': 1},\n",
    "    'Worry about newborn': {'No': 0, 'Yes': 1},\n",
    "    'Relax/sleep when newborn is tended': {'No': 0, 'Yes': 1},\n",
    "    'Relax/sleep when the newborn is asleep': {'No': 0, 'Yes': 1},\n",
    "    'Angry after latest child birth': {'No': 0, 'Yes': 1},\n",
    "    'Depression before pregnancy': {'Negative': 0, 'Positive': 1},\n",
    "    'Depression during pregnancy': {'Negative': 0, 'Positive': 1},\n",
    "    'Major changes or losses during pregnancy': {'No': 0, 'Yes': 1},\n",
    "    'Abuse': {'No': 0, 'Yes': 1},\n",
    "    'Trust and share feelings': {'No': 0, 'Yes': 1}\n",
    "}\n",
    "\n",
    "# Apply binary mappings\n",
    "for col, mapping in binary_mappings.items():\n",
    "    df[col] = df[col].map(mapping)\n",
    "\n",
    "# Ordinal categories\n",
    "ordinal_categories = {\n",
    "    'Monthly income before latest pregnancy': ['None', 'Less than 5000', '5000 to 10000', '10000 to 20000', '20000 to 30000', 'More than 30000'],\n",
    "    'Current monthly income': ['None', 'Less than 5000', '5000 to 10000', '10000 to 20000', '20000 to 30000', 'More than 30000'],\n",
    "    \"Husband's monthly income\": ['None', 'Less than 5000', '5000 to 10000', '10000 to 20000', '20000 to 30000', 'More than 30000'],\n",
    "    'Total children': ['One', 'Two', 'More than two'],\n",
    "    'Number of household members': ['2 to 5', '6 to 8', '9 or more'],\n",
    "    'Pregnancy length': ['Less than 5 months', '8 months', '9 months', '10 months'],\n",
    "    'Age of newborn': ['0 to 6 months', '6 months to 1 year', '1 year to 1.5 year', 'Older than 1.5 year'],\n",
    "    'Age of immediate older children': ['None', '1yr to 3yr', '4yr to 6yr', '7yr to 12yr', '13yr or more'],\n",
    "    'Recieved Support': ['None', 'Low', 'Medium', 'High'],\n",
    "    'Need for Support': ['None', 'Low', 'Medium', 'High'],\n",
    "    'Relationship with the in-laws': ['Bad', 'Neutral', 'Good'],\n",
    "    'Relationship with husband': ['Bad', 'Neutral', 'Good'],\n",
    "    'Relationship with the newborn': ['Bad', 'Neutral', 'Good'],\n",
    "    'Relationship between father and newborn': ['Bad', 'Neutral', 'Good'],\n",
    "    'Feeling about motherhood': ['Sad', 'Neutral', 'Happy']\n",
    "}\n",
    "\n",
    "# Standardize relationship values\n",
    "for col in ['Relationship with the in-laws', 'Relationship with husband', 'Relationship with the newborn', 'Relationship between father and newborn']:\n",
    "    df[col] = df[col].replace({'Friendly': 'Good', 'Very good': 'Good', 'Poor': 'Bad'})\n",
    "\n",
    "# Use significant features for preprocessing, fallback to all if none are significant\n",
    "selected_features = list(set(significant_features)) if significant_features else numerical_cols + binary_cols + ordinal_cols + categorical_cols\n",
    "print(f\"\\nSelected features for preprocessing: {selected_features}\")\n",
    "\n",
    "# Update column lists to include only significant features\n",
    "numerical_cols = [col for col in numerical_cols if col in selected_features]\n",
    "binary_cols = [col for col in binary_cols if col in selected_features]\n",
    "ordinal_cols = [col for col in ordinal_cols if col in selected_features]\n",
    "categorical_cols = [col for col in categorical_cols if col in selected_features]\n",
    "\n",
    "# Debugging\n",
    "print(\"\\nPreprocessing Debugging:\")\n",
    "print(\"Shape of X before preprocessing:\", df[selected_features].shape)\n",
    "print(\"Columns in X:\", df[selected_features].columns.tolist())\n",
    "print(\"Numerical columns:\", numerical_cols)\n",
    "print(\"Binary columns:\", binary_cols)\n",
    "print(\"Ordinal columns:\", ordinal_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "if ordinal_cols:\n",
    "    categories_list = [ordinal_categories[col] for col in ordinal_cols]\n",
    "    print(\"Ordinal categories length:\", len(categories_list))\n",
    "    print(\"Ordinal categories:\", categories_list)\n",
    "else:\n",
    "    print(\"No ordinal columns selected.\")\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(categories=[ordinal_categories[col] for col in ordinal_cols], handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "]) if ordinal_cols else None\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Binary pipeline: impute with most frequent\n",
    "binary_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Build transformers list dynamically\n",
    "transformers = []\n",
    "if numerical_cols:\n",
    "    transformers.append(('num', numeric_pipeline, numerical_cols))\n",
    "if ordinal_cols:\n",
    "    transformers.append(('ord', ordinal_pipeline, ordinal_cols))\n",
    "if categorical_cols:\n",
    "    transformers.append(('cat', categorical_pipeline, categorical_cols))\n",
    "if binary_cols:\n",
    "    transformers.append(('bin', binary_pipeline, binary_cols))\n",
    "\n",
    "# Final column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=transformers,\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Split features and targets\n",
    "X = df[selected_features]\n",
    "y_phq9 = df['PHQ9_encoded']\n",
    "y_epds = df['EPDS_encoded']\n",
    "\n",
    "# Fit and transform\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "X_preprocessed = pd.DataFrame(\n",
    "    X_preprocessed,\n",
    "    columns=preprocessor.get_feature_names_out(),\n",
    "    index=X.index  # This keeps the row alignment with y\n",
    ")\n",
    "\n",
    "# Save preprocessor for future use\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
    "\n",
    "print(f\"\\nPreprocessed feature matrix shape: {X_preprocessed.shape}\")\n",
    "print(\"Analysis and preprocessing complete. All plots saved in 'plots' directory. Ready for modeling.\")\n",
    "\n",
    "# The rest of the notebook continues unchanged with modeling and SMOTE usage\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
