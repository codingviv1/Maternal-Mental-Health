{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ecfd70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr, chi2_contingency\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5530a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and cleaned.\n",
      "DataFrame shape: (800, 48)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Data for Postpartum Depression Prediction in Bangladesh/PPD_dataset.csv')\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.replace(\"’\", \"'\").str.replace(\"‘\", \"'\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(['sr', 'PHQ9 Score', 'EPDS Score'], axis=1)\n",
    "\n",
    "# Standardize 'Total children'\n",
    "df['Total children'] = df['Total children'].str.lower().str.strip()\n",
    "df['Total children'] = df['Total children'].replace({\n",
    "    'more than two': 'More than two',\n",
    "    'more than Two': 'More than two'\n",
    "})\n",
    "\n",
    "# Fix 'Received Support' typo\n",
    "if 'Received Support' in df.columns and 'Recieved Support' not in df.columns:\n",
    "    df = df.rename(columns={'Received Support': 'Recieved Support'})\n",
    "\n",
    "print(\"Data loaded and cleaned.\")\n",
    "print(\"DataFrame shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b54a35f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing 8 NaNs in PHQ9_encoded with mode: 2.0\n",
      "Imputing 317 NaNs in EPDS_encoded with mode: 2.0\n",
      "PHQ9_encoded distribution:\n",
      " PHQ9_encoded\n",
      "2.0    246\n",
      "1.0    230\n",
      "3.0    132\n",
      "0.0    103\n",
      "4.0     89\n",
      "Name: count, dtype: int64\n",
      "EPDS_encoded distribution:\n",
      " EPDS_encoded\n",
      "2.0    668\n",
      "0.0     86\n",
      "1.0     46\n",
      "Name: count, dtype: int64\n",
      "Columns defined, targets cleaned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\AppData\\Local\\Temp\\ipykernel_12176\\2741711673.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(mode, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Define columns\n",
    "numerical_cols = ['Age', 'Number of the latest pregnancy']\n",
    "binary_cols = [\n",
    "    'Residence', 'Marital status', 'Family type', 'Pregnancy plan', 'Regular checkups',\n",
    "    'Fear of pregnancy', 'Mode of delivery', 'Gender of newborn', 'Birth compliancy',\n",
    "    'Breastfeed', 'Newborn illness', 'Worry about newborn', 'Relax/sleep when newborn is tended',\n",
    "    'Relax/sleep when the newborn is asleep', 'Angry after latest child birth',\n",
    "    'Depression before pregnancy', 'Depression during pregnancy', 'Major changes or losses during pregnancy',\n",
    "    'Abuse', 'Trust and share feelings'\n",
    "]\n",
    "ordinal_cols = [\n",
    "    'Monthly income before latest pregnancy', 'Current monthly income', \"Husband's monthly income\",\n",
    "    'Total children', 'Number of household members', 'Pregnancy length', 'Age of newborn',\n",
    "    'Age of immediate older children', 'Recieved Support', 'Need for Support',\n",
    "    'Relationship with the in-laws', 'Relationship with husband', 'Relationship with the newborn',\n",
    "    'Relationship between father and newborn', 'Feeling about motherhood'\n",
    "]\n",
    "categorical_cols = [\n",
    "    'Education Level', 'Occupation before latest pregnancy', 'Occupation After Your Latest Childbirth',\n",
    "    \"Husband's education level\", 'Addiction', 'Disease before pregnancy', 'History of pregnancy loss',\n",
    "    'Diseases during pregnancy', 'Feeling for regular activities'\n",
    "]\n",
    "target_cols = ['PHQ9 Result', 'EPDS Result']\n",
    "\n",
    "# Encode targets\n",
    "phq9_mapping = {'Minimal': 0, 'Mild': 1, 'Moderate': 2, 'Moderately Severe': 3, 'Severe': 4}\n",
    "epds_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "df['PHQ9_encoded'] = df['PHQ9 Result'].map(phq9_mapping)\n",
    "df['EPDS_encoded'] = df['EPDS Result'].map(epds_mapping)\n",
    "\n",
    "# Handle NaNs in targets\n",
    "for col in ['PHQ9_encoded', 'EPDS_encoded']:\n",
    "    nans = df[col].isna().sum()\n",
    "    if nans > 0:\n",
    "        mode = df[col].mode()[0]\n",
    "        print(f\"Imputing {nans} NaNs in {col} with mode: {mode}\")\n",
    "        df[col].fillna(mode, inplace=True)\n",
    "\n",
    "# Check target distributions\n",
    "print(\"PHQ9_encoded distribution:\\n\", df['PHQ9_encoded'].value_counts(dropna=False))\n",
    "print(\"EPDS_encoded distribution:\\n\", df['EPDS_encoded'].value_counts(dropna=False))\n",
    "\n",
    "print(\"Columns defined, targets cleaned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f13d9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Spearman Correlation with Targets ===\n",
      "Age vs PHQ9: corr=0.022, p=0.525\n",
      "Age vs EPDS: corr=-0.008, p=0.826\n",
      "Number of the latest pregnancy vs PHQ9: corr=-0.030, p=0.396\n",
      "Number of the latest pregnancy vs EPDS: corr=-0.009, p=0.804\n",
      "\n",
      "=== Chi-Square Tests with Targets ===\n",
      "Residence vs PHQ9: p=0.360\n",
      "Residence vs EPDS: p=0.415\n",
      "Marital status vs PHQ9: p=0.169\n",
      "Marital status vs EPDS: p=0.489\n",
      "Family type vs PHQ9: p=0.002\n",
      "Family type vs EPDS: p=0.012\n",
      "Pregnancy plan vs PHQ9: p=0.023\n",
      "Pregnancy plan vs EPDS: p=0.001\n",
      "Regular checkups vs PHQ9: p=0.150\n",
      "Regular checkups vs EPDS: p=0.050\n",
      "Fear of pregnancy vs PHQ9: p=0.000\n",
      "Fear of pregnancy vs EPDS: p=0.000\n",
      "Mode of delivery vs PHQ9: p=0.303\n",
      "Mode of delivery vs EPDS: p=0.198\n",
      "Gender of newborn vs PHQ9: p=0.874\n",
      "Gender of newborn vs EPDS: p=0.917\n",
      "Birth compliancy vs PHQ9: p=0.009\n",
      "Birth compliancy vs EPDS: p=0.011\n",
      "Breastfeed vs PHQ9: p=0.431\n",
      "Breastfeed vs EPDS: p=0.170\n",
      "Newborn illness vs PHQ9: p=0.776\n",
      "Newborn illness vs EPDS: p=0.003\n",
      "Worry about newborn vs PHQ9: p=0.000\n",
      "Worry about newborn vs EPDS: p=0.000\n",
      "Relax/sleep when newborn is tended vs PHQ9: p=0.000\n",
      "Relax/sleep when newborn is tended vs EPDS: p=0.037\n",
      "Relax/sleep when the newborn is asleep vs PHQ9: p=0.000\n",
      "Relax/sleep when the newborn is asleep vs EPDS: p=0.000\n",
      "Angry after latest child birth vs PHQ9: p=0.000\n",
      "Angry after latest child birth vs EPDS: p=0.000\n",
      "Depression before pregnancy vs PHQ9: p=0.000\n",
      "Depression before pregnancy vs EPDS: p=0.000\n",
      "Depression during pregnancy vs PHQ9: p=0.000\n",
      "Depression during pregnancy vs EPDS: p=0.000\n",
      "Major changes or losses during pregnancy vs PHQ9: p=0.000\n",
      "Major changes or losses during pregnancy vs EPDS: p=0.000\n",
      "Abuse vs PHQ9: p=0.000\n",
      "Abuse vs EPDS: p=0.000\n",
      "Trust and share feelings vs PHQ9: p=0.000\n",
      "Trust and share feelings vs EPDS: p=0.000\n",
      "Monthly income before latest pregnancy vs PHQ9: p=0.056\n",
      "Monthly income before latest pregnancy vs EPDS: p=0.723\n",
      "Current monthly income vs PHQ9: p=0.791\n",
      "Current monthly income vs EPDS: p=0.758\n",
      "Husband's monthly income vs PHQ9: p=0.664\n",
      "Husband's monthly income vs EPDS: p=0.000\n",
      "Total children vs PHQ9: p=0.743\n",
      "Total children vs EPDS: p=0.075\n",
      "Number of household members vs PHQ9: p=0.010\n",
      "Number of household members vs EPDS: p=0.007\n",
      "Pregnancy length vs PHQ9: p=0.928\n",
      "Pregnancy length vs EPDS: p=0.208\n",
      "Age of newborn vs PHQ9: p=0.357\n",
      "Age of newborn vs EPDS: p=0.304\n",
      "Age of immediate older children vs PHQ9: p=0.034\n",
      "Age of immediate older children vs EPDS: p=0.057\n",
      "Recieved Support vs PHQ9: p=0.000\n",
      "Recieved Support vs EPDS: p=0.000\n",
      "Need for Support vs PHQ9: p=0.001\n",
      "Need for Support vs EPDS: p=0.000\n",
      "Relationship with the in-laws vs PHQ9: p=0.000\n",
      "Relationship with the in-laws vs EPDS: p=0.000\n",
      "Relationship with husband vs PHQ9: p=0.000\n",
      "Relationship with husband vs EPDS: p=0.000\n",
      "Relationship with the newborn vs PHQ9: p=0.000\n",
      "Relationship with the newborn vs EPDS: p=0.000\n",
      "Relationship between father and newborn vs PHQ9: p=0.000\n",
      "Relationship between father and newborn vs EPDS: p=0.000\n",
      "Feeling about motherhood vs PHQ9: p=0.000\n",
      "Feeling about motherhood vs EPDS: p=0.000\n",
      "Education Level vs PHQ9: p=0.000\n",
      "Education Level vs EPDS: p=0.000\n",
      "Occupation before latest pregnancy vs PHQ9: p=0.223\n",
      "Occupation before latest pregnancy vs EPDS: p=0.704\n",
      "Occupation After Your Latest Childbirth vs PHQ9: p=0.147\n",
      "Occupation After Your Latest Childbirth vs EPDS: p=0.170\n",
      "Husband's education level vs PHQ9: p=0.000\n",
      "Husband's education level vs EPDS: p=0.000\n",
      "Addiction vs PHQ9: p=0.575\n",
      "Addiction vs EPDS: p=0.301\n",
      "Disease before pregnancy vs PHQ9: p=0.871\n",
      "Disease before pregnancy vs EPDS: p=0.973\n",
      "History of pregnancy loss vs PHQ9: p=0.000\n",
      "History of pregnancy loss vs EPDS: p=0.328\n",
      "Diseases during pregnancy vs PHQ9: p=0.000\n",
      "Diseases during pregnancy vs EPDS: p=0.000\n",
      "Feeling for regular activities vs PHQ9: p=0.003\n",
      "Feeling for regular activities vs EPDS: p=0.090\n",
      "\n",
      "Significant features: ['Feeling about motherhood', 'Major changes or losses during pregnancy', 'Birth compliancy', 'Newborn illness', 'History of pregnancy loss', 'Relax/sleep when the newborn is asleep', 'Pregnancy plan', 'Relationship between father and newborn', 'Education Level', 'Relax/sleep when newborn is tended', 'Worry about newborn', 'Trust and share feelings', 'Depression during pregnancy', \"Husband's monthly income\", 'Angry after latest child birth', 'Abuse', 'Regular checkups', 'Recieved Support', 'Relationship with the newborn', 'Feeling for regular activities', 'Fear of pregnancy', 'Relationship with husband', 'Number of household members', \"Husband's education level\", 'Relationship with the in-laws', 'Need for Support', 'Depression before pregnancy', 'Diseases during pregnancy', 'Family type', 'Age of immediate older children']\n",
      "Statistical analysis completed.\n"
     ]
    }
   ],
   "source": [
    "# Statistical analysis to define significant_features\n",
    "significant_features = []\n",
    "\n",
    "# Spearman correlation for numerical features\n",
    "print(\"\\n=== Spearman Correlation with Targets ===\")\n",
    "for col in numerical_cols:\n",
    "    corr_phq9, p_phq9 = spearmanr(df[col], df['PHQ9_encoded'])\n",
    "    corr_epds, p_epds = spearmanr(df[col], df['EPDS_encoded'])\n",
    "    print(f\"{col} vs PHQ9: corr={corr_phq9:.3f}, p={p_phq9:.3f}\")\n",
    "    print(f\"{col} vs EPDS: corr={corr_epds:.3f}, p={p_epds:.3f}\")\n",
    "    if p_phq9 < 0.05 or p_epds < 0.05:\n",
    "        significant_features.append(col)\n",
    "\n",
    "# Chi-square tests for categorical/binary/ordinal features\n",
    "print(\"\\n=== Chi-Square Tests with Targets ===\")\n",
    "def chi_square_test(col, target):\n",
    "    contingency = pd.crosstab(df[col], df[target])\n",
    "    chi2, p, _, _ = chi2_contingency(contingency)\n",
    "    return p\n",
    "\n",
    "for col in binary_cols + ordinal_cols + categorical_cols:\n",
    "    p_phq9 = chi_square_test(col, 'PHQ9 Result')\n",
    "    p_epds = chi_square_test(col, 'EPDS Result')\n",
    "    print(f\"{col} vs PHQ9: p={p_phq9:.3f}\")\n",
    "    print(f\"{col} vs EPDS: p={p_epds:.3f}\")\n",
    "    if p_phq9 < 0.05 or p_epds < 0.05:\n",
    "        significant_features.append(col)\n",
    "\n",
    "significant_features = list(set(significant_features))\n",
    "print(f\"\\nSignificant features: {significant_features}\")\n",
    "\n",
    "print(\"Statistical analysis completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08c03ae0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:413\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_range\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mValueError\u001b[39m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m df[col] = df[col].map(mapping)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df[col].isna().sum() > \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     mode = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mImputed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[col].isna().sum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m NaNs in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m     df[col].fillna(mode, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1124\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1236\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:415\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    413\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._range.index(new_key)\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "# Binary mappings\n",
    "binary_mappings = {\n",
    "    'Residence': {'City': 0, 'Village': 1},\n",
    "    'Marital status': {'Married': 0, 'Divorced': 1},\n",
    "    'Family type': {'Nuclear': 0, 'Joint': 1},\n",
    "    'Pregnancy plan': {'No': 0, 'Yes': 1},\n",
    "    'Regular checkups': {'No': 0, 'Yes': 1},\n",
    "    'Fear of pregnancy': {'No': 0, 'Yes': 1},\n",
    "    'Mode of delivery': {'Normal Delivery': 0, 'Caesarean Section': 1},\n",
    "    'Gender of newborn': {'Boy': 0, 'Girl': 1},\n",
    "    'Birth compliancy': {'No': 0, 'Yes': 1},\n",
    "    'Breastfeed': {'No': 0, 'Yes': 1},\n",
    "    'Newborn illness': {'No': 0, 'Yes': 1},\n",
    "    'Worry about newborn': {'No': 0, 'Yes': 1},\n",
    "    'Relax/sleep when newborn is tended': {'No': 0, 'Yes': 1},\n",
    "    'Relax/sleep when the newborn is asleep': {'No': 0, 'Yes': 1},\n",
    "    'Angry after latest child birth': {'No': 0, 'Yes': 1},\n",
    "    'Depression before pregnancy': {'Negative': 0, 'Positive': 1},\n",
    "    'Depression during pregnancy': {'Negative': 0, 'Positive': 1},\n",
    "    'Major changes or losses during pregnancy': {'No': 0, 'Yes': 1},\n",
    "    'Abuse': {'No': 0, 'Yes': 1},\n",
    "    'Trust and share feelings': {'No': 0, 'Yes': 1}\n",
    "}\n",
    "\n",
    "# Apply binary mappings and impute NaNs\n",
    "for col, mapping in binary_mappings.items():\n",
    "    df[col] = df[col].map(mapping)\n",
    "    if df[col].isna().sum() > 0:\n",
    "        mode = df[col].mode()[0]\n",
    "        print(f\"Imputed {df[col].isna().sum()} NaNs in {col} with mode: {mode}\")\n",
    "        df[col].fillna(mode, inplace=True)\n",
    "\n",
    "# Ordinal categories\n",
    "ordinal_categories = {\n",
    "    'Monthly income before latest pregnancy': ['None', 'Less than 5000', '5000 to 10000', '10000 to 20000', '20000 to 30000', 'More than 30000'],\n",
    "    'Current monthly income': ['None', 'Less than 5000', '5000 to 10000', '10000 to 20000', '20000 to 30000', 'More than 30000'],\n",
    "    \"Husband's monthly income\": ['None', 'Less than 5000', '5000 to 10000', '10000 to 20000', '20000 to 30000', 'More than 30000'],\n",
    "    'Total children': ['One', 'Two', 'More than two'],\n",
    "    'Number of household members': ['2 to 5', '6 to 8', '9 or more'],\n",
    "    'Pregnancy length': ['Less than 5 months', '8 months', '9 months', '10 months'],\n",
    "    'Age of newborn': ['0 to 6 months', '6 months to 1 year', '1 year to 1.5 year', 'Older than 1.5 year'],\n",
    "    'Age of immediate older children': ['None', '1yr to 3yr', '4yr to 6yr', '7yr to 12yr', '13yr or more'],\n",
    "    'Recieved Support': ['None', 'Low', 'Medium', 'High'],\n",
    "    'Need for Support': ['None', 'Low', 'Medium', 'High'],\n",
    "    'Relationship with the in-laws': ['Bad', 'Neutral', 'Good'],\n",
    "    'Relationship with husband': ['Bad', 'Neutral', 'Good'],\n",
    "    'Relationship with the newborn': ['Bad', 'Neutral', 'Good'],\n",
    "    'Relationship between father and newborn': ['Bad', 'Neutral', 'Good'],\n",
    "    'Feeling about motherhood': ['Sad', 'Neutral', 'Happy']\n",
    "}\n",
    "\n",
    "# Standardize relationship values\n",
    "for col in ['Relationship with the in-laws', 'Relationship with husband', 'Relationship with the newborn', 'Relationship between father and newborn']:\n",
    "    df[col] = df[col].replace({'Friendly': 'Good', 'Very good': 'Good', 'Poor': 'Bad'})\n",
    "\n",
    "# Use significant features for preprocessing\n",
    "selected_features = list(set(significant_features)) if significant_features else numerical_cols + binary_cols + ordinal_cols + categorical_cols\n",
    "print(\"\\nSelected features for preprocessing:\", selected_features)\n",
    "\n",
    "# Update column lists\n",
    "numerical_cols = [col for col in numerical_cols if col in selected_features]\n",
    "binary_cols = [col for col in binary_cols if col in selected_features]\n",
    "ordinal_cols = [col for col in ordinal_cols if col in selected_features]\n",
    "categorical_cols = [col for col in categorical_cols if col in selected_features]\n",
    "\n",
    "# Debugging\n",
    "print(\"\\nPreprocessing Debugging:\")\n",
    "print(\"Shape of X before preprocessing:\", df[selected_features].shape)\n",
    "print(\"Columns in X:\", df[selected_features].columns.tolist())\n",
    "print(\"Numerical columns:\", numerical_cols)\n",
    "print(\"Binary columns:\", binary_cols)\n",
    "print(\"Ordinal columns:\", ordinal_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "if ordinal_cols:\n",
    "    categories_list = [ordinal_categories[col] for col in ordinal_cols]\n",
    "    print(\"Ordinal categories length:\", len(categories_list))\n",
    "    print(\"Ordinal categories:\", categories_list)\n",
    "else:\n",
    "    print(\"No ordinal columns selected. Skipping ordinal pipeline.\")\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "binary_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Only create ordinal pipeline if ordinal_cols is non-empty\n",
    "if ordinal_cols:\n",
    "    ordinal_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OrdinalEncoder(categories=[ordinal_categories[col] for col in ordinal_cols], handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "else:\n",
    "    ordinal_pipeline = None\n",
    "\n",
    "# Build transformers list dynamically\n",
    "transformers = []\n",
    "if numerical_cols:\n",
    "    transformers.append(('num', numeric_pipeline, numerical_cols))\n",
    "if ordinal_cols and ordinal_pipeline:\n",
    "    transformers.append(('ord', ordinal_pipeline, ordinal_cols))\n",
    "if categorical_cols:\n",
    "    transformers.append(('cat', categorical_pipeline, categorical_cols))\n",
    "if binary_cols:\n",
    "    transformers.append(('bin', binary_pipeline, binary_cols))\n",
    "\n",
    "# Check if transformers is empty\n",
    "if not transformers:\n",
    "    raise ValueError(\"No columns selected for preprocessing. Check significant_features or column definitions.\")\n",
    "\n",
    "# Final column transformer\n",
    "preprocessor = ColumnTransformer(transformers=transformers, remainder='drop')\n",
    "\n",
    "# Split features and targets\n",
    "X = df[selected_features]\n",
    "y_phq9 = df['PHQ9_encoded']\n",
    "y_epds = df['EPDS_encoded']\n",
    "\n",
    "# Fit and transform\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "X_preprocessed = pd.DataFrame(\n",
    "    X_preprocessed,\n",
    "    columns=preprocessor.get_feature_names_out(),\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "# Check for NaNs\n",
    "print(\"NaNs in X_preprocessed:\", X_preprocessed.isna().sum().sum())\n",
    "\n",
    "# Save preprocessor\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
    "\n",
    "print(f\"\\nPreprocessed feature matrix shape: {X_preprocessed.shape}\")\n",
    "print(\"Preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504c309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import os\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('models_new', exist_ok=True)\n",
    "os.makedirs('results_new', exist_ok=True)\n",
    "\n",
    "# Modeling setup\n",
    "targets = {'PHQ9_encoded': y_phq9, 'EPDS_encoded': y_epds}\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "for target_name, y in targets.items():\n",
    "    print(f\"\\n=== Modeling for {target_name} ===\")\n",
    "    # Align data\n",
    "    drop = pd.concat([X_preprocessed, y], axis=1)\n",
    "    # Drop NaNs\n",
    "    drop = data_model.dropna(subset=[target_name])\n",
    "    \n",
    "    X_clean = data_model.drop(columns=[target_name])\n",
    "    y_clean = data_model[target_name]\n",
    "    \n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_clean, y_clean, test_size=0.2, random_state=RANDOM_STATE, stratify=y_clean\n",
    "    )\n",
    "    \n",
    "    # Check NaNs\n",
    "    print(\"NaNs in X_train:\", X_train.isna().sum().sum())\n",
    "    print(\"NaNs in X_test:\", X_test.isna().sum().sum())\n",
    "    \n",
    "    # Apply SMOTE\n",
    "    smote = SMOTE(random_state=RANDOM_STATE)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Model\n",
    "    model = RandomForestClassifier(n_estimators=1000, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"\\n=== {target_name} Results ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Minimal', 'Mild', target_name=='Moderate', 'Moderately Severe', 'Severe'] if 'target_name' == 'PHQ9_encoded' else ['Low', 'Medium', 'High']))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = figure(figsize=(8, 6))\n",
    "    sns.cmheatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix for {target_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(f'results/{target_name}_rf_confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save model\n",
    "    plt.joblib.dump(model, f'models/{target_name}_rf_rf_model.pkl')\n",
    "    \n",
    "    print(f\"Model saved for {target_name}.\")\n",
    "print(\"\\nModeling completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
